{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ðŸŽ¨ Fashion Accessory Recommender - Outfit Encoder Training\n",
        "\n",
        "**Author:** Pabasara11  \n",
        "**Date:** 2025-12-19  \n",
        "**GPU:** Tesla T4 (Free Google Colab)  \n",
        "**Training Time:** 6-8 hours  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Š What This Notebook Does:\n",
        "\n",
        "1. âœ… Connects to your GitHub repository\n",
        "2. âœ… Downloads the fashion dataset from Google Drive\n",
        "3. âœ… Trains ResNet-152 outfit feature extractor\n",
        "4. âœ… Saves model checkpoints to Google Drive\n",
        "5. âœ… Generates training statistics and visualizations\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ Setup Requirements:\n",
        "\n",
        "- Google Account (free)\n",
        "- GitHub repository:  `fashion-accessory-recommender`\n",
        "- Dataset uploaded to Google Drive\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## ðŸ”§ STEP 1: Environment Setup"
      ]
    },
    {
      "cell_type":  "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(\"ðŸ” Checking GPU availability...\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available:  {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"âš ï¸ No GPU detected!  Go to Runtime > Change runtime type > T4 GPU\")\n",
        "    device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id":  "install_deps"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "print(\"ðŸ“¦ Installing dependencies...\")\n",
        "!pip install -q transformers timm pillow tqdm"
      ]
    },
    {
      "cell_type":  "markdown",
      "metadata":  {
        "id": "mount_drive"
      },
      "source": [
        "## ðŸ’¾ STEP 2: Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount"
      },
      "outputs":  [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project folder in Google Drive\n",
        "import os\n",
        "project_drive = '/content/drive/MyDrive/FashionAI'\n",
        "os.makedirs(project_drive, exist_ok=True)\n",
        "os.makedirs(f\"{project_drive}/checkpoints\", exist_ok=True)\n",
        "os.makedirs(f\"{project_drive}/data\", exist_ok=True)\n",
        "print(f\"âœ… Google Drive mounted at: {project_drive}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clone_repo"
      },
      "source": [
        "## ðŸ“¥ STEP 3: Clone GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "git_clone"
      },
      "outputs": [],
      "source": [
        "# Clone your repository\n",
        "!git clone https://github.com/Pabasara11/fashion-accessory-recommender.git\n",
        "%cd fashion-accessory-recommender\n",
        "\n",
        "# Verify structure\n",
        "!ls -la backend/models/\n",
        "! ls -la backend/core/"
      ]
    },
    {
      "cell_type":  "markdown",
      "metadata":  {
        "id": "upload_data"
      },
      "source": [
        "## ðŸ“Š STEP 4: Upload & Extract Dataset\n",
        "\n",
        "**OPTION A:** Upload from your local machine (if dataset < 2GB)  \n",
        "**OPTION B:** Download directly from Kaggle (recommended)"
      ]
    },
    {
      "cell_type":  "code",
      "execution_count": null,
      "metadata": {
        "id": "kaggle_setup"
      },
      "outputs": [],
      "source": [
        "# OPTION B: Download from Kaggle (RECOMMENDED)\n",
        "\n",
        "# 1. Get Kaggle API token:\n",
        "#    - Go to https://www.kaggle.com/settings\n",
        "#    - Click \"Create New API Token\"\n",
        "#    - Download kaggle.json\n",
        "\n",
        "# 2. Upload kaggle.json to Colab (use file upload button on left sidebar)\n",
        "\n",
        "# 3. Set up Kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle. json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 4. Download dataset\n",
        "print(\"ðŸ“¥ Downloading dataset from Kaggle...\")\n",
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-dataset\n",
        "\n",
        "# 5. Extract\n",
        "print(\"ðŸ“¦ Extracting dataset...\")\n",
        "! unzip -q fashion-product-images-dataset.zip -d data/raw/fashion-dataset\n",
        "print(\"âœ… Dataset ready! \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count":  null,
      "metadata": {
        "id": "verify_data"
      },
      "outputs": [],
      "source": [
        "# Verify dataset\n",
        "import os\n",
        "data_path = 'data/raw/fashion-dataset'\n",
        "if os.path.exists(f\"{data_path}/images\"):\n",
        "    num_images = len(os.listdir(f\"{data_path}/images\"))\n",
        "    print(f\"âœ… Found {num_images: ,} images\")\n",
        "if os.path.exists(f\"{data_path}/styles. csv\"):\n",
        "    print(f\"âœ… Found styles.csv\")\n",
        "else:\n",
        "    print(\"âŒ Dataset structure incorrect!\")"
      ]
    },
    {
      "cell_type":  "markdown",
      "metadata":  {
        "id": "preprocess"
      },
      "source": [
        "## ðŸ”„ STEP 5:  Preprocess Dataset"
      ]
    },
    {
      "cell_type":  "code",
      "execution_count": null,
      "metadata": {
        "id": "run_preprocessing"
      },
      "outputs": [],
      "source": [
        "# Run preprocessing script\n",
        "%cd /content/fashion-accessory-recommender/backend\n",
        "\n",
        "# Update paths in preprocessor for Colab\n",
        "import sys\n",
        "sys. path.append('/content/fashion-accessory-recommender/backend')\n",
        "\n",
        "from utils.data_preprocessor import FashionDataPreprocessor\n",
        "\n",
        "# Initialize\n",
        "preprocessor = FashionDataPreprocessor(\n",
        "    raw_data_path='/content/fashion-accessory-recommender/data/raw/fashion-dataset',\n",
        "    processed_data_path='/content/fashion-accessory-recommender/data/processed/accessories'\n",
        ")\n",
        "\n",
        "# Run full pipeline\n",
        "stats = preprocessor.run_full_pipeline()\n",
        "\n",
        "print(\"\\nâœ… Preprocessing complete!\")\n",
        "print(f\"Train images: {stats['train_images']}\")\n",
        "print(f\"Val images: {stats['val_images']}\")"
      ]
    },
    {
      "cell_type":  "markdown",
      "metadata":  {
        "id": "train"
      },
      "source":  [
        "## ðŸš€ STEP 6: Train Outfit Encoder"
      ]
    },
    {
      "cell_type":  "code",
      "execution_count": null,
      "metadata": {
        "id": "training"
      },
      "outputs": [],
      "source": [
        "# Import training module\n",
        "import sys\n",
        "sys.path.append('/content/fashion-accessory-recommender/backend')\n",
        "\n",
        "from core.train_outfit_encoder import OutfitEncoderTrainer\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = OutfitEncoderTrainer(\n",
        "    data_dir='/content/fashion-accessory-recommender/data/processed/accessories',\n",
        "    output_dir=f\"{project_drive}/checkpoints\",\n",
        "    device='cuda' if torch.cuda. is_available() else 'cpu'\n",
        ")\n",
        "\n",
        "# Start training\n",
        "print(\"ðŸš€ Starting training...\")\n",
        "print(\"â±ï¸ Estimated time: 6-8 hours on GPU\")\n",
        "print(\"ðŸ’¡ You can close this tab - training will continue! \")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "trainer.train(\n",
        "    num_epochs=20,\n",
        "    phase1_epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize"
      },
      "source": [
        "## ðŸ“Š STEP 7: Visualize Training Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id":  "plot_results"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load training history\n",
        "with open(f\"{project_drive}/checkpoints/training_history.json\", 'r') as f:\n",
        "    history = json.load(f)\n",
        "\n",
        "# Plot training curves\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss plot\n",
        "axes[0].plot(history['train_losses'], label='Train Loss', linewidth=2)\n",
        "axes[0].plot(history['val_losses'], label='Val Loss', linewidth=2)\n",
        "axes[0]. set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training & Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "axes[1].plot(history['train_accs'], label='Train Acc', linewidth=2)\n",
        "axes[1].plot(history['val_accs'], label='Val Acc', linewidth=2)\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy (%)')\n",
        "axes[1].set_title('Training & Validation Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{project_drive}/checkpoints/training_curves.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nðŸŽ‰ Training Complete! \")\n",
        "print(f\"Best Validation Accuracy: {history['best_val_acc']:.2f}%\")\n",
        "print(f\"\\nðŸ“ Saved files:\")\n",
        "print(f\"   - best_model.pth\")\n",
        "print(f\"   - final_model.pth\")\n",
        "print(f\"   - training_history.json\")\n",
        "print(f\"   - training_curves. png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_model"
      },
      "source": [
        "## ðŸ§ª STEP 8: Test Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test"
      },
      "outputs":  [],
      "source": [
        "from models.outfit_encoder import OutfitFeatureExtractor\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Load trained model\n",
        "checkpoint = torch.load(f\"{project_drive}/checkpoints/best_model.pth\")\n",
        "\n",
        "model = OutfitFeatureExtractor(\n",
        "    num_classes=checkpoint['num_classes'],\n",
        "    pretrained=False\n",
        ")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "model.to('cuda' if torch.cuda. is_available() else 'cpu')\n",
        "\n",
        "print(f\"âœ… Model loaded!  Validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
        "\n",
        "# Test on sample image\n",
        "import random\n",
        "import os\n",
        "\n",
        "val_dir = '/content/fashion-accessory-recommender/data/processed/accessories/val'\n",
        "categories = os.listdir(val_dir)\n",
        "sample_category = random.choice(categories)\n",
        "sample_images = os.listdir(f\"{val_dir}/{sample_category}\")\n",
        "sample_image_path = f\"{val_dir}/{sample_category}/{random.choice(sample_images)}\"\n",
        "\n",
        "# Load and transform image\n",
        "transform = model.get_transform()\n",
        "image = Image.open(sample_image_path).convert('RGB')\n",
        "image_tensor = transform(image).unsqueeze(0).to(model.backbone.fc. weight.device)\n",
        "\n",
        "# Get prediction\n",
        "with torch.no_grad():\n",
        "    features, logits = model(image_tensor)\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    pred_class = torch.argmax(probs, dim=1).item()\n",
        "    confidence = probs[0, pred_class].item() * 100\n",
        "\n",
        "# Display result\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Predicted: {checkpoint['category_mapping'][pred_class]}\\nConfidence: {confidence:.1f}%\\nTrue: {sample_category}\", fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nâœ… Model is working correctly! \")"
      ]
    },
    {
      "cell_type":  "markdown",
      "metadata":  {
        "id": "download"
      },
      "source": [
        "## ðŸ’¾ STEP 9: Download Trained Model\n",
        "\n",
        "Your models are saved in Google Drive at: `/content/drive/MyDrive/FashionAI/checkpoints/`\n",
        "\n",
        "To download to your local machine:\n",
        "1. Go to Google Drive\n",
        "2. Navigate to `FashionAI/checkpoints/`\n",
        "3. Download `best_model.pth`\n",
        "4. Place it in your local project:  `backend/models/checkpoints/`"
      ]
    }
  ],
  "metadata":  {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}